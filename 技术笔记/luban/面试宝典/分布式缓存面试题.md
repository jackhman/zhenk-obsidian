  

## 1. 如何提升系统业务数据访问性能？谈谈你对缓存的理解？

缓存构建的基本思想是利用时间局限性原理，通过空间换时间来达到加速数据获取的目的，同时由于缓存空间的成本较高，在实际设计架构中还要考虑访问延迟和成本的权衡问题。

  

缓存的优势：

- 提升访问性能
- 降低网络拥堵
- 减轻服务负载
- 增强可扩展性

  

缓存的风险：

- 增加了系统的复杂度
- 缓存相比原始 DB 存储和运维的成本更高
- 存在一致性问题

  

业务系统读写缓存有 3 种模式：

- Cache Aside（旁路缓存）
- Read/Write Through（读写穿透）
- Write Behind Caching（异步缓存写入）

#### Cache Aside模式

1.Write: 更新 DB 后，直接将 key 从 cache 中删除，然后由 DB 驱动缓存数据的更新；

2.Read: 是先读 cache，如果 cache 没有，则读 DB，同时将从 DB 中读取的数据回写到 cache。

特点：

确保数据以DB 结果为准

适用场景：

对数据一致性要求比较高的业务，或者是缓存数据更新比较复杂的业务，比如需要通过多个原始数据进行计算后设置的缓存数据

  

#### Read/Write Through模式

1. Write: 存储服务收到业务应用的写请求时，会首先查 cache，如果数据在 cache 中不存在，则只更新 DB，如果数据在 cache 中存在，则先更新 cache，然后更新 DB。

2. Read: 存储服务收到读请求时，如果命中 cache 直接返回，否则先从 DB 加载，回写到 cache 后返回响应。

特点：

- 存储服务封装了所有的数据处理细节，业务应用端代码只用关注业务逻辑本身，系统的隔离性更佳。
- 进行写操作时，如果 cache 中没有数据则不更新，有缓存数据才更新，内存效率更高。

适用场景：

用户最新Feed列表

  

#### Write Behind Caching模式

1.Write: 只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB

2.Read: 如果命中 cache 直接返回，否则先从 DB 加载，回写到 cache 后返回响应。

特点：

写性能最高，定期异步刷新，存在数据丢失概率

适用场景：

适合变更频率特别高，但对一致性要求不太高的业务，特别是可以合并写请求的业务，比如对一些计数业务

  

## 2. 如何处理缓存失效、缓存穿透与缓存雪崩

#### 缓存失效

问题描述：

业务访问时，如果大量的 key 同时过期，很多缓存数据访问都会 miss，进而穿透到 DB，DB 的压力就会明显上升，由于 DB 的性能较差，只在缓存的 1%~2% 以下，这样请求的慢查率会明显上升。

业务场景：

同一批火车票售卖时，系统会一次性加载到缓存，如果缓存写入时，过期时间按照预先设置的过期值，那过期时间到期后，系统就会因缓存失效出现变慢的问题。新业务上线时，会进行缓存预热，也会一次性加载大批热数据。

解决方案：

设计缓存的过期时间时，使用公式：过期时间=base 时间+随机时间，让数据在未来一段时间内慢慢过期，避免瞬时全部过期，对 DB 造成过大压力

#### 缓存穿透

问题描述：

有特殊访客在查询一个不存在的 key，导致每次查询都会穿透到 DB，如果这个特殊访客再控制一批肉机，持续访问系统里不存在的 key，就会对 DB 产生很大的压力，从而影响正常服务。

业务场景：

通过不存在的 UID 访问用户，通过不存在的车次 ID 查看购票信息

  

解决方案：

1.查询这些不存在的数据时，第一次查 DB，虽然没查到结果返回 NULL，仍然记录这个 key 到缓存，只是这个 key 对应的 value 是一个特殊设置的值。                                                                                            改进： 设置很短的过期时间，将这些不存在的 key 存在一个独立的公共缓存。

  

2.构建一个 BloomFilter 缓存过滤器，记录全量数据，这样访问数据时，可以直接通过 BloomFilter 判断这个 key 是否存在，如果不存在直接返回即可，根本无需查缓存和 DB。

  

#### 缓存雪崩

问题描述：

缓存雪崩是指部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。

按照缓存是否 rehash分两种情况：

- 缓存不支持 rehash 导致的系统雪崩不可用
- 缓存支持 rehash 导致的缓存雪崩不可用

业务场景：

微博、Twitter 在突发流量洪峰时crash。机架断电，导致业务缓存多个节点宕机，大量请求直接打到 DB，也导致 DB 过载而阻塞，整个系统异常。

解决方案：

1.对业务 DB 的访问增加读写开关，当发现 DB 请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读 DB 的请求进行 failfast 立即返回，待 DB 恢复后再打开读开关。（优先保证写，同时支持部分读）

2.对缓存增加多个副本，缓存异常或请求 miss 后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。

3.对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。

  

## 3. 如何处理缓存数据不一致和并发竞争？

#### 数据不一致

问题描述：

同一份数据，可能会同时存在 DB 和缓存之中。那就有可能发生，DB 和缓存的数据不一致。如果缓存有多个副本，多个缓存副本里的数据也可能会发生不一致现象。

业务场景：

在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和 DB 的数据不一致。缓存 rehash 时，某个缓存机器反复异常，多次上下线，更新请求多次 rehash。这样，一份数据存在多个节点，且每次 rehash 只更新某个节点，导致一些缓存节点产生脏数据。

解决方案：

1.cache 更新失败后，可以进行重试，如果重试失败，则将失败的 key 写入队列机服务，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性。

2.缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。

3.不采用 rehash 策略，而采用缓存分层策略，尽量避免脏数据产生。

#### 数据并发竞争

问题描述：

数据并发竞争，是指在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询 DB，导致 DB 压力大增的现象。

业务场景：

购票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。

解决方案：

1.使用全局锁。当缓存请求 miss 后，先尝试加全局锁，只有加全局锁成功的线程，才可以到 DB 去加载数据。其他进程/线程在读取缓存数据 miss 时，如果发现这个 key 有全局锁，就进行等待，待之前的线程将数据从 DB 回种到缓存后，再从缓存获取。

2.对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份，从而减少数据并发竞争的情况。

## 4. 如何应对Hot Key和Big Key引发的问题？

#### Hot key

问题描述：

对于大多数互联网系统，数据是分冷热的。在突发事件发生时，大量用户同时去访问突发热点信息（ Hot key ），这个突发热点信息所在的缓存节点就很容易出现过载和卡顿现象，甚至会被 Crash。

业务场景：

明星结婚、离婚、出轨这种特殊突发事件，奥运、春节这些重大活动或节日，秒杀、双12、618 等线上促销活动

解决方案：

1.利用大数据找出Hot key，将这些Hot  key 进行分散处理，比如一个Hot  key 名字叫 hotkey，可以被分散为 hotkey#1、hotkey#2、hotkey#3，……hotkey#n，这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载。

2. key 的名字不变，对缓存提前进行多副本+多级结合的缓存架构设计。

3. 如果热 key 较多，还可以通过监控体系对缓存的 SLA 实时监控，通过快速扩容来减少Hot key 的冲击。

4. 业务端还可以使用本地缓存，将这些Hot key 记录在本地缓存，来减少对远程缓存的冲击。

#### Big key

问题描述：

在缓存访问时，部分 Key 的 Value 过大，读写、加载易超时的现象。

业务场景：

互联网系统中需要保存用户最新1万个粉丝的业务，一个用户个人信息缓存，包括基本资料、关系图谱计数、发 feed 统计等，微博用户发表 1千字甚至更长的微博内容

解决方案：

1.如果数据存在 memcached 中，可以设计一个缓存阀值，当 value 的长度超过阀值，则对内容启用压缩。

2.如果数据存在 Redis 中，对Big key拆分，如下：

big list： list1、list2、...listN

big hash：可以做二次的hash，例如hash%100

日期：key20190320、key20190321、key_20190322

3. 对Big key设置较长的过期时间，缓存内部在淘汰 key 时，同等条件下，尽量不淘汰这些大 key