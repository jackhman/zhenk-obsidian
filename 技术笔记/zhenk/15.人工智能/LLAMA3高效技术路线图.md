微调：Llama factory微调出一个模型
量化：Llama.cpp把这个模型量化的比较小，不需要太多的显卡就可以推理使用了[GitHub - ggerganov/llama.cpp: LLM inference in C/C++](https://github.com/ggerganov/llama.cpp)
接入智能体：轻量化的框架Phidata做本地知识库、部署上线[What is phidata? - Phidata](https://docs.phidata.com/introduction)
[GitHub - phidatahq/phidata: Add memory, knowledge and tools to LLMs](https://github.com/phidatahq/phidata)
